{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_imports import *\n",
    "from ocr_extractor import extract_text_from_pdf\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "# LLM Models\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from pydantic import BaseModel, Field, AfterValidator, WithJsonSchema\n",
    "import instructor\n",
    "\n",
    "# Typing\n",
    "from typing import Optional, Iterable, List, Annotated\n",
    "from datetime import date\n",
    "\n",
    "# Print\n",
    "from pprint import pprint\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter password in the VS Code prompt at the top of your VS Code window!\n",
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "# Setup OpenAI\n",
    "if os.getenv(\"OPEN_AI_KEY\") is None:\n",
    "    if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "        print(\"Please enter password in the VS Code prompt at the top of your VS Code window!\")\n",
    "    \n",
    "    os.environ['OPENAI_API_KEY'] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"Doesn't look like an API key\"\n",
    "print(\"OpenAI API key configured\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the structure of a resume\n",
    "\n",
    "Create the structure to help LLMs scrape necessary data from the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_validator(day: int):\n",
    "    if day == None:\n",
    "        day = 15\n",
    "    if day > 31 or day < 0:\n",
    "        raise ValueError(\"Day not in range\")\n",
    "    return day\n",
    "    \n",
    "\n",
    "def month_validator(month: int):\n",
    "    if month == None:\n",
    "        month = 6\n",
    "        \n",
    "    if month > 12 or month < 0:\n",
    "        raise ValueError(\"Month not in range\")\n",
    "\n",
    "    return month\n",
    "\n",
    "\n",
    "\n",
    "class ForgivingDate(BaseModel):\n",
    "    day: int = Annotated[\n",
    "        int, \n",
    "        AfterValidator(day_validator),\n",
    "        WithJsonSchema({\n",
    "            'type': 'int',\n",
    "            'description': 'the day (optional)'\n",
    "        })\n",
    "    ]\n",
    "    month: int = Annotated[\n",
    "        int, \n",
    "        AfterValidator(month_validator),\n",
    "        WithJsonSchema({\n",
    "            'type': 'int',\n",
    "            'description': 'the month (optional)'\n",
    "        })\n",
    "    ]\n",
    "    year: int\n",
    "\n",
    "    # def __init__(self, date: date):\n",
    "    #     self.day = day_validator(date.day)\n",
    "    #     self.month = month_validator(date.month)\n",
    "    #     self.year = date.year\n",
    "\n",
    "\n",
    "\n",
    "class DateRange(BaseModel):\n",
    "    start: ForgivingDate\n",
    "    end: ForgivingDate = Field(description='Date of the end', default=ForgivingDate(day=date.today().day, month=date.today().month, year=date.today().year))\n",
    "\n",
    "\n",
    "class Skill(BaseModel):\n",
    "    name: str = Field(description=\"Extract the technical tools in the following text. Technical tools are generally in 2-3 words\")\n",
    "    years: int = Field(description='Years of experience deducted from the (number of days between the dates)/365 and rounded up')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Experience(BaseModel):\n",
    "    dates: DateRange\n",
    "    title: str = Field(description='The name of the role')\n",
    "    company: str = Field(description='The employer')\n",
    "    skills: List[Skill]\n",
    "    description:str = Field(description='spell check all these sentences. Do not summarize anything')\n",
    "\n",
    "\n",
    "class Education(BaseModel):\n",
    "    college: str = Field(description='Institution from which the person received their degree')\n",
    "    \n",
    "    dates: DateRange\n",
    "\n",
    "\n",
    "class Contact(BaseModel):\n",
    "    phone_number: str \n",
    "    email: str \n",
    "    location: str = Field(\n",
    "        default_factory=str, \n",
    "        description='Complete street address wherever possible.'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Candidate(BaseModel):\n",
    "    name: str\n",
    "    contact: Contact\n",
    "    education: Education\n",
    "    \n",
    "    experiences: List[Experience]\n",
    "\n",
    "class OptionalCandidate(BaseModel):\n",
    "    result: Optional[Candidate] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting a PDF \n",
    "\n",
    "Extract PDF of a resume for a quick RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Number of pages: 1\n",
      "/Users/paramesh/miniconda3/envs/resume-extractor/lib/python3.12/site-packages/pydantic/json_schema.py:2099: PydanticJsonSchemaWarning: Default value typing.Annotated[int, AfterValidator(func=<function day_validator at 0x10c9cd300>), WithJsonSchema(json_schema={'type': 'int', 'description': 'the day (optional)'}, mode=None)] is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/Users/paramesh/miniconda3/envs/resume-extractor/lib/python3.12/site-packages/pydantic/json_schema.py:2099: PydanticJsonSchemaWarning: Default value typing.Annotated[int, AfterValidator(func=<function month_validator at 0x10c9cf9c0>), WithJsonSchema(json_schema={'type': 'int', 'description': 'the month (optional)'}, mode=None)] is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "# Get instructed\n",
    "text_chunk = extract_text_from_pdf(SETTINGS['source_pdf_file'])\n",
    "\n",
    "\n",
    "# install client\n",
    "client = instructor.patch(OpenAI(), mode=instructor.Mode.MD_JSON)\n",
    "\n",
    "\n",
    "# extractions\n",
    "extraction = client.chat.completions.create(\n",
    "    model=SETTINGS['model']['name'],\n",
    "    response_model = OptionalCandidate,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': f'Your role is to extract information from the following resume. The present is {date.today()}'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': text_chunk\n",
    "        }\n",
    "    ],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": {\n",
      "        \"name\": \"Hemanth Vikash Kannan Rajan\",\n",
      "        \"contact\": {\n",
      "            \"phone_number\": \"+1 540-449-8971\",\n",
      "            \"email\": \"hemanthv@vt.edu\",\n",
      "            \"location\": \"Brooklyn NYC - 11226\"\n",
      "        },\n",
      "        \"education\": {\n",
      "            \"college\": \"Virginia Tech\",\n",
      "            \"dates\": {\n",
      "                \"start\": {\n",
      "                    \"day\": 1,\n",
      "                    \"month\": 8,\n",
      "                    \"year\": 2016\n",
      "                },\n",
      "                \"end\": {\n",
      "                    \"day\": 1,\n",
      "                    \"month\": 5,\n",
      "                    \"year\": 2020\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"experiences\": [\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2021\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 21,\n",
      "                        \"month\": 3,\n",
      "                        \"year\": 2024\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Core Data Scientist\",\n",
      "                \"company\": \"Moshman Research\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"ML/DL algorithms\",\n",
      "                        \"years\": 3\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"RNN model\",\n",
      "                        \"years\": 3\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"ML algorithm\",\n",
      "                        \"years\": 3\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Data visualization\",\n",
      "                        \"years\": 3\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Javascript\",\n",
      "                        \"years\": 3\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Designing and training custom ML/DL algorithms for a climber weight prediction system for a large corporate client. Building another custom RNN model on a dataset made with about 50 diverse windmill climbers. Trained an ML algorithm with 97% test accuracy using Keras and Scipy for integration into an embedded system, using physics-based feature extraction. Performed ROI analysis for the Data Science wing of the company and brought an additional client in less than a year. Managed the design and implementation of a year-long data visualization project for the Space Force. Designed and built the Commander\\u2019s Dashboard using Javascript for custom charts and radar. Implemented data visualization strategies to meet the client\\u2019s expectations and flexibly change details in the design process using tools like Figma and Adobe XD.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 8,\n",
      "                        \"year\": 2020\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2021\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Lead Data Scientist\",\n",
      "                \"company\": \"Klara\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"skincare recommendation engine\",\n",
      "                        \"years\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"data acquisition\",\n",
      "                        \"years\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"K-Means clustering algorithm\",\n",
      "                        \"years\": 1\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Headed a team of 4+ data scientists to build a skincare recommendation engine using a set of prediction algorithms on PyTorch, according to the client\\u2019s requirements. Introduced 6 new methods of data acquisition and got it approved at the shareholders\\u2019 meeting. Built a custom K-Means clustering algorithm to group all of Klara\\u2019s clientele based on their skin/hair type.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 1,\n",
      "                        \"year\": 2018\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2020\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Python Developer Intern\",\n",
      "                \"company\": \"Secure Identity Services (SIS)\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"web testing architecture\",\n",
      "                        \"years\": 2\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"application development\",\n",
      "                        \"years\": 2\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Java unit tests\",\n",
      "                        \"years\": 2\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Created an alternate web testing architecture using Python with Selenium. Built an application to manage about 35,000 Duo 2-factor authentication users on Python using Duo\\u2019s REST API. Tested University-wide applications using Java unit tests using Selenium and Cucumber. Built an alternate grid system to test all the applications and deployed test cases in Docker containers.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 1,\n",
      "                        \"year\": 2020\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2020\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Machine Learning Researcher\",\n",
      "                \"company\": \"Virginia Tech\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"credibility detection algorithm\",\n",
      "                        \"years\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"feature engineering\",\n",
      "                        \"years\": 1\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Created an algorithm with 94% accuracy to detect the credibility of news articles using a custom classifier model. Trained the Random Forest Classifier model that had an accuracy 5% more than the best research paper in that discipline. Engineered about 22 features using NLTK in Python.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 8,\n",
      "                        \"year\": 2018\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2020\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Research Head\",\n",
      "                \"company\": \"REMind\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"iOS application development\",\n",
      "                        \"years\": 2\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"data management\",\n",
      "                        \"years\": 2\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Built an iOS application using SwiftUI that shows the user their sleep quality based on data collected using the Apple Watch. Managed about 10 beta test users\\u2019 data on Firebase and trained a neural network to figure out the similarities between the dream description and sleep data using TensorFlow.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 6,\n",
      "                        \"year\": 2019\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 8,\n",
      "                        \"year\": 2019\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Machine Learning Researcher\",\n",
      "                \"company\": \"Unmanned Systems Lab, Virginia Tech\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"object detection algorithm\",\n",
      "                        \"years\": 0\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"image processing\",\n",
      "                        \"years\": 0\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"Trained an object detection algorithm (YOLOv2) on a custom COCO dataset to help detect objects and possible threats in the air and used ROS to incorporate the trained image set onto the aircraft. Scraped background images and foreground images from Google using a Python scraper. Wrote a Python script that would super-impose the foreground images on random background images to create a synthetic COCO dataset.\"\n",
      "            },\n",
      "            {\n",
      "                \"dates\": {\n",
      "                    \"start\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 8,\n",
      "                        \"year\": 2018\n",
      "                    },\n",
      "                    \"end\": {\n",
      "                        \"day\": 1,\n",
      "                        \"month\": 5,\n",
      "                        \"year\": 2019\n",
      "                    }\n",
      "                },\n",
      "                \"title\": \"Data Analysis Researcher\",\n",
      "                \"company\": \"Cyber-Human Systems, Virginia Tech\",\n",
      "                \"skills\": [\n",
      "                    {\n",
      "                        \"name\": \"data acquisition software development\",\n",
      "                        \"years\": 1\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"prediction algorithm development\",\n",
      "                        \"years\": 1\n",
      "                    }\n",
      "                ],\n",
      "                \"description\": \"As a member of the UI team, built a data acquisition software for college students to annotate Tweets. Used HTML5 and CSS to build a user interface for the web survey. Using PythonAnywhere, built the backend for the survey and recorded the survey responses to a MySQL database. Built a prediction algorithm to classify hate speech on a few social media platforms using the results from the Twitter web survey that had been conducted.\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"error\": false,\n",
      "    \"message\": \"Parsed successfully\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_result = extraction.model_dump_json()\n",
    "print(json.dumps(json.loads(json_result), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFile =open('../data/example.json', 'w')\n",
    "writeFile.write(json_result)\n",
    "writeFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
